{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3714ed75-b4b1-49be-acea-47a2649194ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, LSTM\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758e5d72-436a-49c4-a5ce-d30bb60068d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets ===\n",
    "tor = pd.read_csv(\"Tor_Clean_Server_Web_Browsing.csv\")\n",
    "nontor = pd.read_csv(\"Non_Tor_Clean_Server_Browsing.csv\")\n",
    "\n",
    "#Remove host-specific features\n",
    "drop_cols = [\"StartTime\",\"EndTime\", \"SrcIP\", \"DstIP\",\n",
    "             \"SrcPort\", \"DstPort\", \"Proto\"]\n",
    "\n",
    "tor_df = tor.drop(columns=drop_cols, errors=\"ignore\")\n",
    "nontor_df = nontor.drop(columns=drop_cols, errors=\"ignore\")\n",
    "# Add labels\n",
    "tor_df[\"label\"] = 1\n",
    "nontor_df[\"label\"] = 0\n",
    "\n",
    "# Balance the datasets (if necessary)\n",
    "min_length = min(len(nontor_df), len(tor_df))\n",
    "nontor_data = nontor_df.iloc[:min_length]\n",
    "tor_data = tor_df.iloc[:min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b65dff-bbae-4127-9c26-5333e2d02e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and shuffle\n",
    "df = pd.concat([tor_data, nontor_data], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Drop columns where all values are 0\n",
    "df = df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf2e060-5a00-48ba-acf2-dd88eab66b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>TotalPackets</th>\n",
       "      <th>TotalBytes</th>\n",
       "      <th>PacketsPerSec</th>\n",
       "      <th>BytesPerSec</th>\n",
       "      <th>FwdPackets</th>\n",
       "      <th>BwdPackets</th>\n",
       "      <th>FwdBytes</th>\n",
       "      <th>BwdBytes</th>\n",
       "      <th>PktLenMin</th>\n",
       "      <th>...</th>\n",
       "      <th>BwdIATMin</th>\n",
       "      <th>BwdIATMax</th>\n",
       "      <th>BwdIATMean</th>\n",
       "      <th>BwdIATStd</th>\n",
       "      <th>TCP_FIN</th>\n",
       "      <th>TCP_SYN</th>\n",
       "      <th>TCP_RST</th>\n",
       "      <th>TCP_PSH</th>\n",
       "      <th>TCP_ACK</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146993</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>13.606097</td>\n",
       "      <td>1115.699980</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258.018587</td>\n",
       "      <td>174</td>\n",
       "      <td>43278</td>\n",
       "      <td>0.674370</td>\n",
       "      <td>167.732102</td>\n",
       "      <td>69</td>\n",
       "      <td>105</td>\n",
       "      <td>27713</td>\n",
       "      <td>15565</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.386624</td>\n",
       "      <td>2.480720</td>\n",
       "      <td>9.776136</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.367096</td>\n",
       "      <td>10</td>\n",
       "      <td>2760</td>\n",
       "      <td>0.964590</td>\n",
       "      <td>266.226918</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>2029</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.294816</td>\n",
       "      <td>2.583222</td>\n",
       "      <td>2.963307</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>12.317668</td>\n",
       "      <td>10</td>\n",
       "      <td>3391</td>\n",
       "      <td>0.811842</td>\n",
       "      <td>275.295617</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>731</td>\n",
       "      <td>2660</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>7.244798</td>\n",
       "      <td>3.071041</td>\n",
       "      <td>3.644868</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>68.072713</td>\n",
       "      <td>14</td>\n",
       "      <td>4821</td>\n",
       "      <td>0.205662</td>\n",
       "      <td>70.821329</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2580</td>\n",
       "      <td>2241</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>46.042406</td>\n",
       "      <td>9.326538</td>\n",
       "      <td>20.525537</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2804 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Duration  TotalPackets  TotalBytes  PacketsPerSec  BytesPerSec  \\\n",
       "0       0.146993             2         164      13.606097  1115.699980   \n",
       "1       0.000000             1          60       0.000000     0.000000   \n",
       "2     258.018587           174       43278       0.674370   167.732102   \n",
       "3       0.000000             1          54       0.000000     0.000000   \n",
       "4      10.367096            10        2760       0.964590   266.226918   \n",
       "...          ...           ...         ...            ...          ...   \n",
       "2799   12.317668            10        3391       0.811842   275.295617   \n",
       "2800    0.000000             1          60       0.000000     0.000000   \n",
       "2801    0.000000             1          60       0.000000     0.000000   \n",
       "2802    0.000000             1          60       0.000000     0.000000   \n",
       "2803   68.072713            14        4821       0.205662    70.821329   \n",
       "\n",
       "      FwdPackets  BwdPackets  FwdBytes  BwdBytes  PktLenMin  ...  BwdIATMin  \\\n",
       "0              1           1        74        90         74  ...   0.000000   \n",
       "1              1           0        60         0         60  ...   0.000000   \n",
       "2             69         105     27713     15565         54  ...   0.000000   \n",
       "3              1           0        54         0         54  ...   0.000000   \n",
       "4              5           5       731      2029         54  ...   0.000000   \n",
       "...          ...         ...       ...       ...        ...  ...        ...   \n",
       "2799           5           5       731      2660         54  ...   0.000101   \n",
       "2800           1           0        60         0         60  ...   0.000000   \n",
       "2801           1           0        60         0         60  ...   0.000000   \n",
       "2802           1           0        60         0         60  ...   0.000000   \n",
       "2803           8           6      2580      2241         54  ...   0.000654   \n",
       "\n",
       "      BwdIATMax  BwdIATMean  BwdIATStd  TCP_FIN  TCP_SYN  TCP_RST  TCP_PSH  \\\n",
       "0      0.000000    0.000000   0.000000        0        0        0        0   \n",
       "1      0.000000    0.000000   0.000000        0        0        0        0   \n",
       "2     46.386624    2.480720   9.776136        1        2        0       88   \n",
       "3      0.000000    0.000000   0.000000        0        0        0        0   \n",
       "4      5.294816    2.583222   2.963307        1        2        0        3   \n",
       "...         ...         ...        ...      ...      ...      ...      ...   \n",
       "2799   7.244798    3.071041   3.644868        1        2        0        3   \n",
       "2800   0.000000    0.000000   0.000000        0        0        0        0   \n",
       "2801   0.000000    0.000000   0.000000        0        0        0        0   \n",
       "2802   0.000000    0.000000   0.000000        0        0        0        0   \n",
       "2803  46.042406    9.326538  20.525537        1        2        0        4   \n",
       "\n",
       "      TCP_ACK  label  \n",
       "0           0      1  \n",
       "1           1      1  \n",
       "2         173      0  \n",
       "3           1      0  \n",
       "4           9      0  \n",
       "...       ...    ...  \n",
       "2799        9      0  \n",
       "2800        1      1  \n",
       "2801        1      1  \n",
       "2802        1      1  \n",
       "2803       13      1  \n",
       "\n",
       "[2804 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70bbe0d-b167-47f5-97f9-c33f800fddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace both +inf and -inf with NaN\n",
    "# df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # Drop any rows that contain NaN (i.e., were inf)\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee9b2d0-436e-40ce-9f82-5603ac737ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81702601-5e2f-4de4-a909-65261b95954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70       281\n",
      "           1       0.68      0.92      0.79       280\n",
      "\n",
      "    accuracy                           0.75       561\n",
      "   macro avg       0.78      0.75      0.74       561\n",
      "weighted avg       0.78      0.75      0.74       561\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77       281\n",
      "           1       0.75      0.87      0.80       280\n",
      "\n",
      "    accuracy                           0.79       561\n",
      "   macro avg       0.80      0.79      0.79       561\n",
      "weighted avg       0.80      0.79      0.79       561\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafiq\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:13:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       281\n",
      "           1       0.74      0.86      0.80       280\n",
      "\n",
      "    accuracy                           0.78       561\n",
      "   macro avg       0.79      0.78      0.78       561\n",
      "weighted avg       0.79      0.78      0.78       561\n",
      "\n",
      "Training MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafiq\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.5791 - loss: 0.8357 - val_accuracy: 0.6347 - val_loss: 0.6502 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.7475 - val_accuracy: 0.5278 - val_loss: 0.6421 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6349 - loss: 0.6669 - val_accuracy: 0.6548 - val_loss: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6373 - loss: 0.6909 - val_accuracy: 0.6637 - val_loss: 0.6041 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6550 - loss: 0.6869 - val_accuracy: 0.6682 - val_loss: 0.5915 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6520 - loss: 0.6278 - val_accuracy: 0.6615 - val_loss: 0.5841 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6594 - loss: 0.6274 - val_accuracy: 0.7016 - val_loss: 0.5643 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6781 - loss: 0.6040 - val_accuracy: 0.6659 - val_loss: 0.5734 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6532 - loss: 0.6012 - val_accuracy: 0.6971 - val_loss: 0.5612 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6586 - loss: 0.6139 - val_accuracy: 0.6860 - val_loss: 0.5545 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6615 - loss: 0.6048 - val_accuracy: 0.6927 - val_loss: 0.5453 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6802 - loss: 0.5829 - val_accuracy: 0.6860 - val_loss: 0.5457 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6706 - loss: 0.5921 - val_accuracy: 0.6748 - val_loss: 0.5492 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6663 - loss: 0.6032 - val_accuracy: 0.6615 - val_loss: 0.5494 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6856 - loss: 0.5622 - val_accuracy: 0.7105 - val_loss: 0.5273 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6884 - loss: 0.5697 - val_accuracy: 0.7016 - val_loss: 0.5173 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6822 - loss: 0.5787 - val_accuracy: 0.6971 - val_loss: 0.5140 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6864 - loss: 0.5423 - val_accuracy: 0.7016 - val_loss: 0.5101 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6718 - loss: 0.5640 - val_accuracy: 0.7327 - val_loss: 0.5074 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7008 - loss: 0.5442 - val_accuracy: 0.7149 - val_loss: 0.5026 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6795 - loss: 0.5734 - val_accuracy: 0.7105 - val_loss: 0.5003 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6661 - loss: 0.5700 - val_accuracy: 0.7416 - val_loss: 0.4997 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6989 - loss: 0.5584 - val_accuracy: 0.7550 - val_loss: 0.4992 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6790 - loss: 0.5721 - val_accuracy: 0.7060 - val_loss: 0.5020 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6872 - loss: 0.5676 - val_accuracy: 0.7528 - val_loss: 0.4960 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6513 - loss: 0.5869 - val_accuracy: 0.7483 - val_loss: 0.4913 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6721 - loss: 0.5727 - val_accuracy: 0.7483 - val_loss: 0.4932 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6794 - loss: 0.5541 - val_accuracy: 0.7506 - val_loss: 0.4973 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6967 - loss: 0.5391 - val_accuracy: 0.7082 - val_loss: 0.4973 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6787 - loss: 0.5725 - val_accuracy: 0.7283 - val_loss: 0.4913 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6759 - loss: 0.5542 - val_accuracy: 0.6993 - val_loss: 0.4915 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6975 - loss: 0.5429 - val_accuracy: 0.6927 - val_loss: 0.4935 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6924 - loss: 0.5497 - val_accuracy: 0.7350 - val_loss: 0.4904 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6808 - loss: 0.5577 - val_accuracy: 0.7283 - val_loss: 0.4895 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7011 - loss: 0.5426 - val_accuracy: 0.7127 - val_loss: 0.4894 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6845 - loss: 0.5583 - val_accuracy: 0.7060 - val_loss: 0.4883 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6791 - loss: 0.5527 - val_accuracy: 0.7105 - val_loss: 0.4875 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6777 - loss: 0.5697 - val_accuracy: 0.7127 - val_loss: 0.4867 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6918 - loss: 0.5383 - val_accuracy: 0.7171 - val_loss: 0.4871 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6773 - loss: 0.5472 - val_accuracy: 0.7216 - val_loss: 0.4866 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6914 - loss: 0.5338 - val_accuracy: 0.7149 - val_loss: 0.4862 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6863 - loss: 0.5514 - val_accuracy: 0.7194 - val_loss: 0.4854 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6874 - loss: 0.5551 - val_accuracy: 0.7194 - val_loss: 0.4851 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7079 - loss: 0.5340 - val_accuracy: 0.7016 - val_loss: 0.4852 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6934 - loss: 0.5414 - val_accuracy: 0.7506 - val_loss: 0.4850 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6815 - loss: 0.5354 - val_accuracy: 0.7238 - val_loss: 0.4853 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6774 - loss: 0.5631 - val_accuracy: 0.7305 - val_loss: 0.4850 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7047 - loss: 0.5431 - val_accuracy: 0.7283 - val_loss: 0.4845 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6739 - loss: 0.5527 - val_accuracy: 0.7327 - val_loss: 0.4851 - learning_rate: 6.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7054 - loss: 0.5327 - val_accuracy: 0.7327 - val_loss: 0.4846 - learning_rate: 6.2500e-05\n",
      "\n",
      "MLP Test Loss: 0.5194188952445984, Test Accuracy: 0.6916220784187317\n",
      "Training CNN...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafiq\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.5552 - loss: 0.9890 - val_accuracy: 0.6281 - val_loss: 0.6689 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6197 - loss: 0.7660 - val_accuracy: 0.5434 - val_loss: 0.6734 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6628 - loss: 0.6623 - val_accuracy: 0.4878 - val_loss: 0.7053 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6479 - loss: 0.6677 - val_accuracy: 0.4766 - val_loss: 0.7186 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6582 - loss: 0.6617 - val_accuracy: 0.4878 - val_loss: 0.7067 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6731 - loss: 0.5837 - val_accuracy: 0.4744 - val_loss: 0.7713 - learning_rate: 5.0000e-04\n",
      "\n",
      "CNN Test Loss: 0.6693329811096191, Test Accuracy: 0.6310160160064697\n",
      "Training RNN...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafiq\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5473 - loss: 0.6819 - val_accuracy: 0.5746 - val_loss: 0.6860 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6371 - loss: 0.6315 - val_accuracy: 0.6771 - val_loss: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6699 - loss: 0.5954 - val_accuracy: 0.6837 - val_loss: 0.6696 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6618 - loss: 0.5827 - val_accuracy: 0.6904 - val_loss: 0.6578 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6673 - loss: 0.5623 - val_accuracy: 0.7016 - val_loss: 0.6510 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6830 - loss: 0.5566 - val_accuracy: 0.7038 - val_loss: 0.6454 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6868 - loss: 0.5438 - val_accuracy: 0.7060 - val_loss: 0.6339 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6655 - loss: 0.5446 - val_accuracy: 0.7216 - val_loss: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6838 - loss: 0.5369 - val_accuracy: 0.7305 - val_loss: 0.6222 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6923 - loss: 0.5264 - val_accuracy: 0.7416 - val_loss: 0.6188 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6632 - loss: 0.5457 - val_accuracy: 0.7261 - val_loss: 0.6146 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6948 - loss: 0.5297 - val_accuracy: 0.7238 - val_loss: 0.6016 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6948 - loss: 0.5013 - val_accuracy: 0.7528 - val_loss: 0.5880 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6936 - loss: 0.5150 - val_accuracy: 0.6949 - val_loss: 0.5851 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6823 - loss: 0.5350 - val_accuracy: 0.7394 - val_loss: 0.5809 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7016 - loss: 0.5240 - val_accuracy: 0.7016 - val_loss: 0.5699 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.5039 - val_accuracy: 0.7372 - val_loss: 0.5592 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6862 - loss: 0.5119 - val_accuracy: 0.7105 - val_loss: 0.5568 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7026 - loss: 0.4996 - val_accuracy: 0.7238 - val_loss: 0.5436 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6988 - loss: 0.5028 - val_accuracy: 0.7439 - val_loss: 0.5312 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7159 - loss: 0.4944 - val_accuracy: 0.7216 - val_loss: 0.5320 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6981 - loss: 0.5167 - val_accuracy: 0.7639 - val_loss: 0.5168 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 0.4937 - val_accuracy: 0.7261 - val_loss: 0.5208 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6926 - loss: 0.5103 - val_accuracy: 0.7639 - val_loss: 0.5291 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6988 - loss: 0.5025 - val_accuracy: 0.7105 - val_loss: 0.5284 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7056 - loss: 0.4961 - val_accuracy: 0.7327 - val_loss: 0.5054 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7163 - loss: 0.4943 - val_accuracy: 0.6949 - val_loss: 0.5090 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7183 - loss: 0.4922 - val_accuracy: 0.7105 - val_loss: 0.4973 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7323 - loss: 0.4722 - val_accuracy: 0.7171 - val_loss: 0.4858 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7102 - loss: 0.4973 - val_accuracy: 0.7394 - val_loss: 0.4751 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7105 - loss: 0.4772 - val_accuracy: 0.7773 - val_loss: 0.4703 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7337 - loss: 0.4850 - val_accuracy: 0.7751 - val_loss: 0.4663 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7351 - loss: 0.4703 - val_accuracy: 0.7706 - val_loss: 0.4633 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7181 - loss: 0.4764 - val_accuracy: 0.7661 - val_loss: 0.4518 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7130 - loss: 0.4862 - val_accuracy: 0.7595 - val_loss: 0.4513 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7407 - loss: 0.4527 - val_accuracy: 0.7617 - val_loss: 0.4446 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7162 - loss: 0.4783 - val_accuracy: 0.7639 - val_loss: 0.4445 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7108 - loss: 0.4881 - val_accuracy: 0.7706 - val_loss: 0.4395 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7314 - loss: 0.4661 - val_accuracy: 0.7684 - val_loss: 0.4365 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7161 - loss: 0.4633 - val_accuracy: 0.7773 - val_loss: 0.4336 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7216 - loss: 0.4568 - val_accuracy: 0.7840 - val_loss: 0.4348 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7395 - loss: 0.4565 - val_accuracy: 0.7840 - val_loss: 0.4313 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7365 - loss: 0.4499 - val_accuracy: 0.7439 - val_loss: 0.4352 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7299 - loss: 0.4589 - val_accuracy: 0.7394 - val_loss: 0.4321 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7261 - loss: 0.4669 - val_accuracy: 0.7305 - val_loss: 0.4340 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7159 - loss: 0.4764 - val_accuracy: 0.7617 - val_loss: 0.4274 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7242 - loss: 0.4623 - val_accuracy: 0.7394 - val_loss: 0.4305 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7463 - loss: 0.4633 - val_accuracy: 0.7461 - val_loss: 0.4236 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7370 - loss: 0.4661 - val_accuracy: 0.7439 - val_loss: 0.4226 - learning_rate: 2.5000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7324 - loss: 0.4560 - val_accuracy: 0.7461 - val_loss: 0.4204 - learning_rate: 2.5000e-04\n",
      "\n",
      "RNN Test Loss: 0.45130655169487, Test Accuracy: 0.7344028353691101\n",
      "\n",
      "Results for Decision Tree: {'0': {'precision': 0.8804347826086957, 'recall': 0.5765124555160143, 'f1-score': 0.6967741935483871, 'support': 281.0}, '1': {'precision': 0.6843501326259946, 'recall': 0.9214285714285714, 'f1-score': 0.7853881278538812, 'support': 280.0}, 'accuracy': 0.7486631016042781, 'macro avg': {'precision': 0.7823924576173451, 'recall': 0.7489705134722928, 'f1-score': 0.7410811607011342, 'support': 561.0}, 'weighted avg': {'precision': 0.7825672211200037, 'recall': 0.7486631016042781, 'f1-score': 0.7410021821500598, 'support': 561.0}}\n",
      "\n",
      "Results for Random Forest: {'0': {'precision': 0.8432203389830508, 'recall': 0.708185053380783, 'f1-score': 0.769825918762089, 'support': 281.0}, '1': {'precision': 0.7476923076923077, 'recall': 0.8678571428571429, 'f1-score': 0.8033057851239669, 'support': 280.0}, 'accuracy': 0.7878787878787878, 'macro avg': {'precision': 0.7954563233376792, 'recall': 0.7880210981189629, 'f1-score': 0.7865658519430279, 'support': 561.0}, 'weighted avg': {'precision': 0.7955414641855321, 'recall': 0.7878787878787878, 'f1-score': 0.7865360124899424, 'support': 561.0}}\n",
      "\n",
      "Results for XGBoost: {'0': {'precision': 0.8347457627118644, 'recall': 0.701067615658363, 'f1-score': 0.7620889748549323, 'support': 281.0}, '1': {'precision': 0.7415384615384616, 'recall': 0.8607142857142858, 'f1-score': 0.7966942148760331, 'support': 280.0}, 'accuracy': 0.7807486631016043, 'macro avg': {'precision': 0.788142112125163, 'recall': 0.7808909506863244, 'f1-score': 0.7793915948654827, 'support': 561.0}, 'weighted avg': {'precision': 0.7882251845861019, 'recall': 0.7807486631016043, 'f1-score': 0.7793607524055709, 'support': 561.0}}\n",
      "\n",
      "Results for MLP: {'accuracy': 0.6916220784187317}\n",
      "\n",
      "Results for CNN: {'accuracy': 0.6310160160064697}\n",
      "\n",
      "Results for RNN: {'accuracy': 0.7344028353691101}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Store results for comparison\n",
    "model_results = {}\n",
    "\n",
    "# 1. Decision Tree\n",
    "print(\"Training Decision Tree...\")\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "model_results['Decision Tree'] = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "model_results['Random Forest'] = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBClassifier(n_estimators=300, max_depth=20, learning_rate=0.01, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "model_results['XGBoost'] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "\n",
    "# 4. MLP (Multi-Layer Perceptron)\n",
    "print(\"Training MLP...\")\n",
    "mlp_model = Sequential([\n",
    "    Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "mlp_model.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nMLP Test Loss: {mlp_loss}, Test Accuracy: {mlp_accuracy}\")\n",
    "model_results['MLP'] = {'accuracy': mlp_accuracy}\n",
    "\n",
    "# 5. CNN (Convolutional Neural Network)\n",
    "print(\"Training CNN...\")\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=128, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"\\nCNN Test Loss: {cnn_loss}, Test Accuracy: {cnn_accuracy}\")\n",
    "model_results['CNN'] = {'accuracy': cnn_accuracy}\n",
    "\n",
    "# 6. RNN (Recurrent Neural Network with LSTM)\n",
    "print(\"Training RNN...\")\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(128, input_shape=(1, X_train.shape[1]), return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=128, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test_rnn, y_test, verbose=0)\n",
    "print(f\"\\nRNN Test Loss: {rnn_loss}, Test Accuracy: {rnn_accuracy}\")\n",
    "model_results['RNN'] = {'accuracy': rnn_accuracy}\n",
    "\n",
    "# Visualize Feature Importance for Tree Models\n",
    "def plot_feature_importance(model, features, title):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    " # plot_feature_importance(rf_model, features, \"Random Forest Feature Importance\")\n",
    " # plot_feature_importance(xgb_model, features, \"XGBoost Feature Importance\")\n",
    "\n",
    "# Print Results Summary\n",
    "for model, results in model_results.items():\n",
    "    print(f\"\\nResults for {model}: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768d281a-d0b3-42db-a2f2-d1efff840f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Randomized Search...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      " Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': False}\n",
      "Best Cross-Val F1: 0.8240925472060925\n",
      "\n",
      " Confusion Matrix:\n",
      "[[197  84]\n",
      " [ 39 241]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8347    0.7011    0.7621       281\n",
      "           1     0.7415    0.8607    0.7967       280\n",
      "\n",
      "    accuracy                         0.7807       561\n",
      "   macro avg     0.7881    0.7809    0.7794       561\n",
      "weighted avg     0.7882    0.7807    0.7794       561\n",
      "\n",
      "\n",
      " Top 10 Most Important Features:\n",
      "1. BwdIATMin: 0.091167\n",
      "2. PktLenStd: 0.058885\n",
      "3. PktLenMax: 0.058838\n",
      "4. PacketsPerSec: 0.056935\n",
      "5. FwdIATMin: 0.056726\n",
      "6. BytesPerSec: 0.048286\n",
      "7. BwdPktLenMax: 0.046527\n",
      "8. IATMean: 0.043527\n",
      "9. IATMin: 0.039910\n",
      "10. BwdPktLenStd: 0.039187\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 1. Prepare data ===\n",
    "# Assuming your dataframe is named df and has a 'label' column\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Store column names before scaling\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# Scale if you already have X_scaled, otherwise create it:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === 2. Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === 3. Define Random Forest & parameter grid ===\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=15,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\" Starting Randomized Search...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf_model = random_search.best_estimator_\n",
    "print(\"\\n Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Val F1:\", random_search.best_score_)\n",
    "\n",
    "# === 4. Evaluate on test set ===\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n",
    "\n",
    "# === 5. Get Top 10 Feature Importances ===\n",
    "importances = best_rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "top_k = 10\n",
    "top_features = [(features[i], importances[i]) for i in indices[:top_k]]\n",
    "\n",
    "print(f\"\\n Top {top_k} Most Important Features:\")\n",
    "for rank, (name, val) in enumerate(top_features, start=1):\n",
    "    print(f\"{rank}. {name}: {val:.6f}\")\n",
    "\n",
    "# === 6. Plot (Top 10 only) ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_k), [importances[i] for i in indices[:top_k]], align='center')\n",
    "plt.yticks(range(top_k), [features[i] for i in indices[:top_k]])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(f\"Top {top_k} Features - Random Forest 100 MB File Transfer (Suchith Server)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9aba93-46df-4002-9c8f-68491252c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2804\n",
      "Number of columns: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a1d8d2-109d-4e9c-a223-289bd9cf6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "['Duration', 'TotalPackets', 'TotalBytes', 'PacketsPerSec', 'BytesPerSec', 'FwdPackets', 'BwdPackets', 'FwdBytes', 'BwdBytes', 'PktLenMin', 'PktLenMax', 'PktLenMean', 'PktLenStd', 'FwdPktLenMin', 'FwdPktLenMax', 'FwdPktLenMean', 'FwdPktLenStd', 'BwdPktLenMin', 'BwdPktLenMax', 'BwdPktLenMean', 'BwdPktLenStd', 'IATMin', 'IATMax', 'IATMean', 'IATStd', 'FwdIATMin', 'FwdIATMax', 'FwdIATMean', 'FwdIATStd', 'BwdIATMin', 'BwdIATMax', 'BwdIATMean', 'BwdIATStd', 'TCP_FIN', 'TCP_SYN', 'TCP_RST', 'TCP_PSH', 'TCP_ACK', 'label']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acddf1-04c7-4ffe-92aa-9f8fd5b41424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f366c-95a0-43cf-893f-bd11e36839d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
